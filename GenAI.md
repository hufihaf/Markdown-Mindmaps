# Generative AI
## Table of Contents
>[**Generative Models**](#generative-models)   
>
>[**Image Generation**](#image-generation) 
>
>[**Audio and Speech Generation**](#audio-and-speech-generation)  
>
>[**Music Generation**](#music-generation)  
>
>[**Code Generation**](#code-generation)  
>
>[**Multimodal Generation**](#multimodal-generation)  

## Generative Models
- What is the difference between discriminative and generative models?
- How do models like GANs (Generative Adversarial Networks), VAEs (Variational Autoencoders), and Transformers generate new data?
- What is a RAG? How can it be best used?

## Image Generation
- How does Stable Diffusion work?

- What is a GAN in image generation?
- How is text-to-image generation achieved (e.g., DALLÂ·E)?

## Audio and Speech Generation
- How do generative models handle prosody and emotion in speech?

- What are common datasets used for training audio generation models?
- How are these models trained?

## Music Generation
- How do models like MusicLM generate music?

- What datasets and encoding strategies are used in AI music generation?

## Code Generation
- How do models like Codex or AlphaCode understand and generate code?

- How is prompt engineering used in AI-assisted programming?
- What are the limitations of generative code models?
- How do we verify the correctness and security of AI-generated code?
- What are common use cases for code generation in industry?

## 'Multimodal' Generation
- What does it mean for a model to be multimodal?

- How are models trained on multiple types of data (e.g., CLIP, GPT-4o)?
- How is alignment ensured between different modalities (text-image, text-video)?
- What are the applications of multimodal generation?
- What are the biggest challenges in building truly multimodal models?
